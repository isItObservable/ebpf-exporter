apiVersion: v1
kind: ConfigMap
metadata:
  name: bpf-exporter-config
  labels:
    app: tracer
data:
  config.yaml: |
    programs:
      # See:
      # * https://github.com/iovisor/bcc/blob/master/tools/biolatency.py
      # * https://github.com/iovisor/bcc/blob/master/tools/biolatency_example.txt
      #
      # See also: bio-tracepoints.yaml
      - name: bio
        metrics:
          histograms:
            - name: bio_latency_seconds
              help: Block IO latency histogram
              table: io_latency
              bucket_type: exp2
              bucket_min: 0
              bucket_max: 26
              bucket_multiplier: 0.000001 # microseconds to seconds
              labels:
                - name: device
                  size: 4
                  decoders:
                    - name: majorminor
                - name: operation
                  size: 4
                  decoders:
                    - name: uint
                    - name: static_map
                      static_map:
                        1: read
                        2: write
                - name: bucket
                  size: 8
                  decoders:
                    - name: uint
            - name: bio_size_bytes
              help: Block IO size histogram with kibibyte buckets
              table: io_size
              bucket_type: exp2
              bucket_min: 0
              bucket_max: 15
              bucket_multiplier: 1024 # kibibytes to bytes
              labels:
                - name: device
                  size: 4
                  decoders:
                    - name: majorminor
                - name: operation
                  size: 4
                  decoders:
                    - name: uint
                    - name: static_map
                      static_map:
                        1: read
                        2: write
                - name: bucket
                  size: 8
                  decoders:
                    - name: uint
        tracepoints:
          block:block_rq_issue: tracepoint__block__block_rq_issue
          block:block_rq_complete: tracepoint__block__block_rq_complete
        code: |
          #include <linux/blkdev.h>
          typedef struct disk_key {
              u32 dev;
              u8 op;
              u64 slot;
          } disk_key_t;
          // Max number of disks we expect to see on the host
          const u8 max_disks = 255;
          // 27 buckets for latency, max range is 33.6s .. 67.1s
          const u8 max_latency_slot = 26;
          // 16 buckets per disk in kib, max range is 16mib .. 32mib
          const u8 max_size_slot = 15;
          // Histograms to record latencies
          BPF_HISTOGRAM(io_latency, disk_key_t, (max_latency_slot + 2) * max_disks);
          // Histograms to record sizes
          BPF_HISTOGRAM(io_size, disk_key_t, (max_size_slot + 2) * max_disks);
          struct key_t {
              dev_t dev;
              sector_t sector;
          };
          struct val_t {
              u64 start;
              u64 bytes;
          };
          // Hash to temporily hold the start time of each bio request, max 10k in-flight by default
          BPF_HASH(start, struct key_t, struct val_t);
          // Generates function tracepoint__block__block_rq_issue
          TRACEPOINT_PROBE(block, block_rq_issue) {
              // blkid generates these and we're not interested in them
              if (args->dev == 0) {
                  return 0;
              }
              struct key_t key = {};
              key.dev = args->dev;
              key.sector = args->sector;
              if (key.sector == -1) {
                key.sector = 0;
              }
              struct val_t val = {};
              val.start = bpf_ktime_get_ns();
              val.bytes = args->bytes;
              start.update(&key, &val);
              return 0;
          }
          // Generates function tracepoint__block__block_rq_complete
          TRACEPOINT_PROBE(block, block_rq_complete) {
              struct key_t key = {};
              key.dev = args->dev;
              key.sector = args->sector;
              if (key.sector == -1) {
                key.sector = 0;
              }
              struct val_t *valp = start.lookup(&key);
              if (valp == 0) {
                  return 0; // missed issue
              }
              // Delta in microseconds
              u64 delta = (bpf_ktime_get_ns() - valp->start) / 1000;
              // Latency histogram key
              u64 latency_slot = bpf_log2l(delta);
              // Cap latency bucket at max value
              if (latency_slot > max_latency_slot) {
                  latency_slot = max_latency_slot;
              }
              disk_key_t latency_key = {};
              latency_key.slot = latency_slot;
              latency_key.dev = new_encode_dev(args->dev);
              // Size in kibibytes
              u64 size_kib = valp->bytes / 1024;
              // Request size histogram key
              u64 size_slot = bpf_log2(size_kib);
              // Cap latency bucket at max value
              if (size_slot > max_size_slot) {
                  size_slot = max_size_slot;
              }
              disk_key_t size_key = {};
              size_key.slot = size_slot;
              size_key.dev = new_encode_dev(args->dev);
              if (args->rwbs[0] == 'W' || args->rwbs[0] == 'S' || args->rwbs[0] == 'F' || args->rwbs[1] == 'W' || args->rwbs[1] == 'S' || args->rwbs[1] == 'F') {
                  latency_key.op = 2;
                  size_key.op    = 2;
              } else {
                  latency_key.op = 1;
                  size_key.op    = 1;
              }
              io_latency.increment(latency_key);
              io_size.increment(size_key);
              // Increment sum keys
              latency_key.slot = max_latency_slot + 1;
              io_latency.increment(latency_key, delta);
              size_key.slot = max_size_slot + 1;
              io_size.increment(size_key, size_kib);
              start.delete(&key);
              return 0;
          }
      - name: runqlat
        metrics:
          histograms:
            - name: run_queue_latency_seconds
              help: Run queue latency histogram
              table: run_queue_latency
              bucket_type: exp2
              bucket_min: 0
              bucket_max: 26
              bucket_multiplier: 0.000001 # microseconds to seconds
              labels:
                - name: bucket
                  size: 8
                  reuse: true
                  decoders:
                    - name: uint
        kprobes:
          ttwu_do_wakeup: trace_ttwu_do_wakeup
          wake_up_new_task: trace_wake_up_new_task
          finish_task_switch: trace_run
        code: |
          #include <linux/sched.h>

          // 27 buckets for latency, max range is 33.6s .. 67.1s
          const u8 max_latency_slot = 26;

          // Histograms to record latencies
          BPF_HISTOGRAM(run_queue_latency, u64, max_latency_slot + 2);

          // Pid to enqueue time map
          BPF_HASH(start, u64);

          // Record enqueue timestamp
          static int trace_enqueue(u32 tgid, u64 pid) {
              if (tgid == 0 && pid == 0) {
                  // Skip swapper kthread
                  return 0;
              }

              u64 ts = bpf_ktime_get_ns();
              start.update(&pid, &ts);

              return 0;
          }

          int trace_wake_up_new_task(struct pt_regs *ctx, struct task_struct *p) {
              return trace_enqueue(p->tgid, p->pid);
          }

          int trace_ttwu_do_wakeup(struct pt_regs *ctx, void* rq, struct task_struct *p, int wake_flags) {
              return trace_enqueue(p->tgid, p->pid);
          }

          // Calculate latency
          int trace_run(struct pt_regs *ctx, struct task_struct *prev) {
              // Treat like an enqueue event and store timestamp
              if (prev->state == TASK_RUNNING) {
                  trace_enqueue(prev->tgid, prev->pid);
              }

              u32 tgid = bpf_get_current_pid_tgid() >> 32;
              u64 pid = bpf_get_current_pid_tgid();

              // Fetch timestamp and calculate delta
              u64 *tsp = start.lookup(&pid);
              if (tsp == 0) {
                  // Missed enqueue
                  return 0;
              }

              // Latency in microseconds
              u64 latency_us = bpf_ktime_get_ns() - *tsp;
              // Skip entries with backwards time: temp workaround for https://github.com/iovisor/bcc/issues/728
              if ((s64) latency_us < 0) {
                start.delete(&pid);
                return 0;
              }
              // Convert to microseconds
              latency_us /= 1000;

              // Latency histogram key
              u64 latency_slot = bpf_log2l(latency_us);

              // Cap latency bucket at max value
              if (latency_slot > max_latency_slot) {
                  latency_slot = max_latency_slot;
              }

              // Increment bucket key
              run_queue_latency.increment(latency_slot);

              // Increment sum key
              run_queue_latency.increment(max_latency_slot + 1, latency_us);

              // Remove enqueued task
              start.delete(&pid);

              return 0;
          }


      - name: drsnoop
        metrics:
          histograms:
            - name: direct_reclaim_latency_seconds
              help: Direct reclaim memory latency histogram
              table: direct_reclaim_latency
              bucket_type: exp2
              bucket_min: 0
              bucket_max: 26
              bucket_multiplier: 0.000001 # microseconds to seconds
              labels:
                - name: app_namespace
                  size: 8
                  reuse: true
                  decoders:
                    - name: kube_podnamespace
                - name: app_container
                  size: 8
                  reuse: false
                  decoders:
                    - name: kube_containername
                - name: bucket
                  size: 8
                  reuse: false
                  decoders:
                    - name: uint
        tracepoints:
          vmscan:mm_vmscan_direct_reclaim_begin: tracepoint__vmscan__mm_vmscan_direct_reclaim_begin
          vmscan:mm_vmscan_direct_reclaim_end: tracepoint__vmscan__mm_vmscan_direct_reclaim_end
        code: |

          #include <uapi/linux/ptrace.h>
          #include <linux/sched.h>
          #include <linux/mmzone.h>

          typedef struct pid_key {
              u64 pid;
              u64 slot;
          } pid_key_t;

          // 27 buckets for latency, max range is 33.6s .. 67.1s
          const u8 max_latency_slot = 26;
          // Histograms to record latencies
          BPF_HISTOGRAM(direct_reclaim_latency, pid_key_t, max_latency_slot + 2);

          struct val_t {
              u64 id;
              u64 ts; // start time
          };
          BPF_HASH(start, u64, struct val_t);

          TRACEPOINT_PROBE(vmscan, mm_vmscan_direct_reclaim_begin) {
              u64 id = bpf_get_current_pid_tgid();
              struct val_t val = {.id = id};
              val.ts = bpf_ktime_get_ns();
              start.update(&id, &val);
              return 0;
          }
          TRACEPOINT_PROBE(vmscan, mm_vmscan_direct_reclaim_end) {
              u64 id = bpf_get_current_pid_tgid();
              u64 pid = id >> 32; // PID is higher part
              struct val_t *valp;
              u64 ts = bpf_ktime_get_ns();
              valp = start.lookup(&id);
              if (valp == NULL) {
                  // missed entry
                  return 0;
              }

              // Latency in microseconds
              u64 latency_us = bpf_ktime_get_ns() - valp->ts;
              // Skip entries with backwards time: temp workaround for https://github.com/iovisor/bcc/issues/728
              if ((s64) latency_us < 0) {
                start.delete(&id);
                return 0;
              }
              // Convert to microseconds
              latency_us /= 1000;

              // Latency histogram key
              u64 latency_slot = bpf_log2l(latency_us);

              // Cap latency bucket at max value
              if (latency_slot > max_latency_slot) {
                  latency_slot = max_latency_slot;
              }

              pid_key_t latency_key = { .pid = pid, .slot = latency_slot };

              // Increment bucket key
              direct_reclaim_latency.increment(latency_key);

              // Increment sum key
              latency_key.slot = max_latency_slot + 1;
              direct_reclaim_latency.increment(latency_key, latency_us);

              start.delete(&id);
              return 0;
          }
      - name: cgroup
        metrics:
          counters:
            - name: cgroup_open_calls_total
              help: Calls to open() from cgroups
              table: counts
              labels:
                - name: cgroup
                  size: 8
                  decoders:
                    - name: uint
                    - name: cgroup
        tracepoints:
          syscalls:sys_enter_open: tracepoint__syscalls__sys_enter_open
        code: |
          BPF_HASH(counts, u64);
          // Generates function tracepoint__syscalls__sys_enter_open
          TRACEPOINT_PROBE(syscalls, sys_enter_open) {
              counts.increment((u64) bpf_get_current_cgroup_id());
              return 0;
          }
      - name: mcevents
        metrics:
          counters:
            - name: mc_event_total
              help: Machine check events
              table: mc_counts
              labels:
                - name: type
                  size: 4
                  decoders:
                    - name: uint
                    - name: static_map
                      static_map:
                        0: err_corrected
                        1: err_uncorrected
                        2: err_deferred
                        3: err_fatal
                        4: info
                - name: middle_layer
                  size: 1
                  decoders:
                    - name: uint
                - name: top_layer
                  size: 1
                  decoders:
                    - name: uint
                - name: lower_layer
                  size: 1
                  decoders:
                    - name: uint
                - name: mc_index
                  size: 1
                  decoders:
                    - name: uint
                - name: label
                  size: 32
                  decoders:
                    - name: string
                - name: msg
                  size: 32
                  decoders:
                    - name: string
        tracepoints:
          ras:mc_event: tracepoint__ras__mc_event
        code: |
          #include <uapi/linux/ptrace.h>
          #include <linux/types.h>
          struct key_t {
              uint type;
              s8 middle_layer;
              s8 top_layer;
              s8 lower_layer;
              s8 mc_index;
              char label[32];
              char msg[32];
          };
          BPF_HASH(mc_counts, struct key_t, u64);
          // Generates function tracepoint__ras__mc_event
          TRACEPOINT_PROBE(ras, mc_event) {
              struct key_t key = {
                  .type = args->error_type,
                  .middle_layer = args->middle_layer,
                  .top_layer = args->top_layer,
                  .lower_layer = args->lower_layer,
                  .mc_index = args->mc_index,
              };
              TP_DATA_LOC_READ_CONST(key.label, label, 32);
              TP_DATA_LOC_READ_CONST(key.msg, msg, 32);
              mc_counts.increment(key);
              return 0;
          }